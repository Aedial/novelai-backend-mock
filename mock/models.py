# generated by fastapi-codegen:
#   filename:  schema.json
#   timestamp: 2022-11-24T02:18:11+00:00

from __future__ import annotations

from enum import Enum
from typing import Any, Dict, List, Optional, Union

from pydantic import BaseModel, Field, confloat, conint, constr


class ApiError(BaseModel):
    statusCode: float
    message: str


class CreateUserRequest(BaseModel):
    recaptcha: str = Field(
        ..., description="ReCAPTCHA response token for the novelai.net domain"
    )
    key: constr(min_length=64) = Field(..., description="Required access key")
    email: Optional[constr(min_length=64, max_length=64)] = Field(
        None, description="SHA-256 hashed email in hexadecimal"
    )
    emailCleartext: Optional[str] = Field(
        None,
        description="Email address (provided as cleartext for email verification, stored hashed)",
    )
    giftkey: Optional[str] = Field(
        None,
        description="Subscription gift key, if provided will be automatically activated upon registration",
    )


class SuccessfulLoginResponse(BaseModel):
    accessToken: str = Field(
        ...,
        description='Access Token to be used in the Authorization header in the format of "Bearer ${accessToken}"',
    )


class LoginRequest(BaseModel):
    key: constr(min_length=64, max_length=64) = Field(
        ..., description="Required access key"
    )


class ChangeAccessKeyRequest(BaseModel):
    currentAccessKey: constr(min_length=64) = Field(
        ..., description="Current access key"
    )
    newAccessKey: constr(min_length=64) = Field(..., description="New access key")
    newEmail: Optional[str] = Field(None, description="New email address")


class EmailVerificationStartRequest(BaseModel):
    email: str


class EmailVerificationRequest(BaseModel):
    verificationToken: constr(min_length=64, max_length=64)


class AccountInformationResponse(BaseModel):
    emailVerified: bool
    emailVerificationLetterSent: bool
    trialActivated: bool
    trialActionsLeft: float
    accountCreatedAt: float


class DeletionStartRequest(BaseModel):
    email: str = Field(..., description="Target email for account deletion")


class DeletionFinishRequest(BaseModel):
    deletionToken: constr(min_length=16) = Field(
        ..., description="Deletion token provided in the email letter"
    )


class RecoveryStartRequest(BaseModel):
    email: str = Field(..., description="Target email for account recovery")


class RecoveryFinishRequest(BaseModel):
    recoveryToken: constr(min_length=16) = Field(
        ..., description="Recovery token provided in the email letter"
    )
    newAccessKey: constr(min_length=64, max_length=64) = Field(
        ..., description="New access key"
    )
    deleteContent: bool = Field(
        ...,
        description="Should the server reset keystore and remove objects of stories and storycontent type?",
    )


class PriorityResponse(BaseModel):
    maxPriorityActions: float
    nextRefillAt: float
    taskPriority: float


class SubscriptionTierPerks(BaseModel):
    maxPriorityActions: float = Field(..., description="Amount of max priority actions")
    startPriority: float = Field(..., description="Start priority amount")
    contextTokens: float = Field(..., description="Amount of granted context tokens")
    unlimitedMaxPriority: bool = Field(..., description="Is max priority unlimited")
    moduleTrainingSteps: float = Field(
        ..., description="Amount of module training steps granted every month"
    )


class SubscriptionAvailableTrainingSteps(BaseModel):
    fixedTrainingStepsLeft: float = Field(
        ...,
        description="Amount of available fixed module training steps left (reset every month)",
    )
    purchasedTrainingSteps: float = Field(
        ..., description="Amount of available purchased module training steps left"
    )


class SubscriptionResponse(BaseModel):
    tier: float = Field(
        ..., description="Subscription internal tier number, see SubscriptionTiers enum"
    )
    active: bool = Field(
        ..., description="Is subscription active as of the moment of the request"
    )
    expiresAt: float = Field(
        ..., description="UNIX timestamp of subscription expiration"
    )
    perks: SubscriptionTierPerks = Field(..., description="Subscription perks")
    paymentProcessorData: Dict[str, Any] = Field(
        ..., description="Payment processor arbitrary data"
    )
    trainingStepsLeft: SubscriptionAvailableTrainingSteps = Field(
        ..., description="Amount of available module training steps left"
    )


class GetKeystoreResponse(BaseModel):
    keystore: Optional[str]


class UserAccountDataResponse(BaseModel):
    priority: PriorityResponse
    subscription: SubscriptionResponse
    keystore: GetKeystoreResponse
    settings: str
    information: AccountInformationResponse


class GiftKeysResponse(BaseModel):
    giftKeys: List[Dict[str, Any]]


class UpdateKeystoreRequest(BaseModel):
    keystore: str = Field(
        ..., description="Base64-encoded keystore (or empty string to clear)"
    )
    changeIndex: Optional[float] = Field(None, description="Current change index")


class UserData(BaseModel):
    id: str = Field(..., description="Object ID")
    meta: constr(max_length=128) = Field(
        ..., description="Accompanying non confidential information"
    )
    data: str = Field(..., description="Base64-encoded buffer")
    lastUpdatedAt: float = Field(..., description="UNIX timestamp")
    changeIndex: float = Field(..., description="Incremental revision of the object")
    type: constr(min_length=1, max_length=16)


class ObjectsResponse(BaseModel):
    objects: List[UserData]


class UserDataInput(BaseModel):
    meta: constr(max_length=128) = Field(
        ..., description="Accompanying non confidential information"
    )
    data: str = Field(..., description="Base64-encoded buffer")
    changeIndex: Optional[float] = Field(None, description="Current change index")


class UserSubmissionInput(BaseModel):
    data: str = Field(..., description="Base64-encoded buffer")
    dataName: constr(max_length=256)
    authorName: constr(max_length=256)
    authorEmail: constr(max_length=256)
    socials: constr(max_length=4096)
    mediums: constr(max_length=4096)
    event: constr(max_length=256)


class UserSubmissionVoteInput(BaseModel):
    id: str


class PaymentProcessor(Enum):
    paddle = "paddle"
    giftkey = "giftkey"
    trial = "trial"


class BindSubscriptionRequest(BaseModel):
    paymentProcessor: PaymentProcessor = Field(
        ..., description="Subscription payment processor"
    )
    subscriptionId: str = Field(..., description="Payment processor ID")


class NewSubscriptionPlan(Enum):
    NONE = "NONE"
    TABLET = "TABLET"
    SCROLL = "SCROLL"
    OPUS = "OPUS"


class ChangeSubscriptionPlanRequest(BaseModel):
    newSubscriptionPlan: NewSubscriptionPlan = Field(..., description="New plan SKU")


class LogitBia(BaseModel):
    __root__: conint(ge=0)


class SequenceItem(BaseModel):
    __root__: conint(ge=0)


class LogitBiasExpItem(BaseModel):
    sequence: List[SequenceItem] = Field(..., min_items=1)
    bias: float
    ensure_sequence_finish: Optional[bool] = None
    generate_once: Optional[bool] = None


class OrderItem(BaseModel):
    __root__: conint(ge=0)


class AiGenerateParameters(BaseModel):
    stop_sequences: Optional[List[List[conint(ge=0)]]] = None
    bad_words_ids: Optional[List[List[conint(ge=0)]]] = None
    use_string: Optional[bool] = Field(
        False,
        description="If false, input and output strings should be Base64-encoded uint16 numbers representing tokens",
    )
    logit_bias: Optional[List[List[LogitBia]]] = None
    logit_bias_exp: Optional[List[LogitBiasExpItem]] = Field(
        None,
        example=[
            {
                "sequence": [9288, 286, 10690],
                "bias": 4,
                "ensure_sequence_finish": True,
                "generate_once": True,
            },
            {"sequence": [9288, 286], "bias": 2},
        ],
    )
    order: Optional[List[OrderItem]] = Field(None, max_items=6, min_items=0)
    repetition_penalty_whitelist: Optional[List[conint(ge=0)]] = None
    temperature: Optional[confloat(ge=0.1, le=100.0)] = None
    min_length: confloat(ge=1.0, le=2048.0)
    max_length: confloat(ge=1.0, le=2048.0)
    do_sample: Optional[bool] = None
    early_stopping: Optional[bool] = None
    num_beams: Optional[float] = None
    top_k: Optional[float] = None
    top_a: Optional[float] = None
    top_p: Optional[float] = None
    typical_p: Optional[float] = None
    repetition_penalty: Optional[float] = None
    pad_token_id: Optional[float] = None
    bos_token_id: Optional[float] = None
    eos_token_id: Optional[float] = None
    length_penalty: Optional[float] = None
    no_repeat_ngram_size: Optional[float] = None
    encoder_no_repeat_ngram_size: Optional[float] = None
    num_return_sequences: Optional[float] = None
    max_time: Optional[float] = None
    use_cache: Optional[bool] = None
    num_beam_groups: Optional[float] = None
    diversity_penalty: Optional[float] = None
    tail_free_sampling: Optional[confloat(ge=0.0, le=1.0)] = None
    repetition_penalty_range: Optional[confloat(ge=0.0, le=2048.0)] = None
    repetition_penalty_slope: Optional[confloat(ge=0.0, le=10.0)] = None
    get_hidden_states: Optional[bool] = None
    repetition_penalty_frequency: Optional[confloat(ge=-2.0, le=2.0)] = None
    repetition_penalty_presence: Optional[confloat(ge=-2.0, le=2.0)] = None
    next_word: Optional[bool] = None
    prefix: Optional[str] = None
    output_nonzero_probs: Optional[bool] = None
    generate_until_sentence: Optional[bool] = None
    num_logprobs: Optional[confloat(ge=0.0, le=30.0)] = None


class Model(Enum):
    field_2_7B = "2.7B"
    field_6B_v4 = "6B-v4"
    euterpe_v2 = "euterpe-v2"
    genji_python_6b = "genji-python-6b"
    genji_jp_6b = "genji-jp-6b"
    genji_jp_6b_v2 = "genji-jp-6b-v2"
    krake_v2 = "krake-v2"
    hypebot = "hypebot"
    infillmodel = "infillmodel"


class Tokenizer(Enum):
    GPT_2 = "gpt2"
    GPT_Genji = "genji"
    PILE = "pile"


model_to_tokenizer = {
    Model.field_2_7B: Tokenizer.GPT_2,
    Model.field_6B_v4: Tokenizer.GPT_2,
    Model.euterpe_v2: Tokenizer.GPT_2,
    Model.genji_python_6b: Tokenizer.GPT_2,
    Model.genji_jp_6b: Tokenizer.GPT_2,
    Model.genji_jp_6b_v2: Tokenizer.GPT_Genji,
    Model.krake_v2: Tokenizer.PILE,
    Model.hypebot: Tokenizer.GPT_2,
    Model.infillmodel: Tokenizer.GPT_2,
}


class AiGenerateRequest(BaseModel):
    input: constr(min_length=1, max_length=14000) = Field(
        ...,
        description="Input for the text generation model",
        example="Text generation example.",
    )
    model: Model = Field(..., description="Used text generation model")
    parameters: AiGenerateParameters = Field(
        ...,
        description="Generation parameters",
        example={
            "use_string": True,
            "temperature": 1,
            "min_length": 10,
            "max_length": 30,
        },
    )


class AiGenerateResponse(BaseModel):
    output: Optional[str] = Field(
        None, description="Output from the text generation model, if defined"
    )
    error: Optional[str] = Field(
        None, description="Error from the generation node, if defined"
    )


class AiGenerateStreamableResponse(BaseModel):
    ptr: Optional[float] = Field(None, description="Incrementing token pointer")
    token: Optional[str] = Field(None, description="Generated token")
    final: Optional[bool] = Field(
        None, description="Set to true if the token is final and the generation ended"
    )
    error: Optional[str] = Field(
        None,
        description="Error from the generation node, if defined. Usually means the end of stream",
    )


class Model1(Enum):
    stable_diffusion = "stable-diffusion"
    nai_diffusion = "nai-diffusion"
    safe_diffusion = "safe-diffusion"
    nai_diffusion_furry = "nai-diffusion-furry"


class AiGenerateImageRequest(BaseModel):
    input: constr(min_length=1, max_length=14000) = Field(
        ...,
        description="Input for the text generation model",
        example="Image generation example.",
    )
    model: Model1 = Field(..., description="Used image generation model")
    parameters: Dict[str, Any] = Field(
        ..., description="Generation parameters (model specific)"
    )


class AiGenerateImageResponse(BaseModel):
    ptr: Optional[float] = Field(None, description="Incrementing version pointer")
    image: Optional[str] = Field(None, description="Generated image in base64")
    final: Optional[bool] = Field(
        None, description="Set to true if the image is final and the generation ended"
    )
    error: Optional[str] = Field(
        None,
        description="Error from the generation node, if defined. Usually means the end of stream",
    )


class OutputItem(BaseModel):
    label: Optional[str] = None
    score: Optional[float] = None


class OutputItem1(BaseModel):
    scores: Optional[List[float]] = None


class AiSequenceClassificationResponse(BaseModel):
    output: Optional[Union[List[OutputItem], OutputItem1]] = Field(
        None,
        description="Output, if defined",
        example=[
            [{"label": "label", "score": 0}],
            {
                "scores": [
                    [
                        0.9600785970687866,
                        0.01683211140334606,
                        0.014393973164260387,
                        0.008695312775671482,
                    ]
                ]
            },
        ],
    )
    error: Optional[str] = Field(None, description="Error, if defined")


class AiRequestImageGenerationTag(BaseModel):
    tag: str
    count: float
    confidence: float


class AiRequestImageGenerationTagsResponse(BaseModel):
    tags: List[AiRequestImageGenerationTag]


class AiModuleTrainRequest(BaseModel):
    data: str = Field(
        ...,
        description="Base64-encoded data if ready or it's a training request, error text if error",
    )
    lr: float = Field(..., description="Learning rate")
    steps: float = Field(..., description="Training steps")
    model: str = Field(
        ..., description="Used text generation model for module training"
    )
    name: constr(max_length=64)
    description: constr(max_length=256)


class Status(Enum):
    pending = "pending"
    training = "training"
    ready = "ready"
    error = "error"


class AiModuleDto(BaseModel):
    data: str = Field(
        ...,
        description="Base64-encoded data if ready or it's a training request, error text if error",
    )
    lr: float = Field(..., description="Learning rate")
    steps: float = Field(..., description="Training steps")
    model: str = Field(
        ..., description="Used text generation model for module training"
    )
    lastUpdatedAt: float = Field(..., description="UNIX timestamp")
    status: Status
    lossHistory: List[float] = Field(..., description="Recorded loss values")
    id: str
    name: constr(max_length=64)
    description: constr(max_length=256)


class BuyTrainingStepsRequest(BaseModel):
    amount: conint(ge=2000, le=10000) = Field(
        ..., description="Amount of module training steps to purchase."
    )


class UserObjectsTypePutResponse(BaseModel):
    pass
